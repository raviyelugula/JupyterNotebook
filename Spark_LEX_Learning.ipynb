{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initiating the SparkContext\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master='local',appName='test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local appName=test1>\n"
     ]
    }
   ],
   "source": [
    "# Verifying the SparkContext\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal_length,sepal_width,petal_length,petal_width,species', '5.1,3.5,1.4,0.2,setosa', '4.9,3.0,1.4,0.2,setosa', '4.7,3.2,1.3,0.2,setosa', '4.6,3.1,1.5,0.2,setosa', '5.0,3.6,1.4,0.2,setosa', '5.4,3.9,1.7,0.4,setosa', '4.6,3.4,1.4,0.3,setosa', '5.0,3.4,1.5,0.2,setosa', '4.4,2.9,1.4,0.2,setosa', '4.9,3.1,1.5,0.1,setosa', '5.4,3.7,1.5,0.2,setosa', '4.8,3.4,1.6,0.2,setosa', '4.8,3.0,1.4,0.1,setosa', '4.3,3.0,1.1,0.1,setosa', '5.8,4.0,1.2,0.2,setosa', '5.7,4.4,1.5,0.4,setosa', '5.4,3.9,1.3,0.4,setosa', '5.1,3.5,1.4,0.3,setosa', '5.7,3.8,1.7,0.3,setosa', '5.1,3.8,1.5,0.3,setosa', '5.4,3.4,1.7,0.2,setosa', '5.1,3.7,1.5,0.4,setosa', '4.6,3.6,1.0,0.2,setosa', '5.1,3.3,1.7,0.5,setosa', '4.8,3.4,1.9,0.2,setosa', '5.0,3.0,1.6,0.2,setosa', '5.0,3.4,1.6,0.4,setosa', '5.2,3.5,1.5,0.2,setosa', '5.2,3.4,1.4,0.2,setosa', '4.7,3.2,1.6,0.2,setosa', '4.8,3.1,1.6,0.2,setosa', '5.4,3.4,1.5,0.4,setosa', '5.2,4.1,1.5,0.1,setosa', '5.5,4.2,1.4,0.2,setosa', '4.9,3.1,1.5,0.1,setosa', '5.0,3.2,1.2,0.2,setosa', '5.5,3.5,1.3,0.2,setosa', '4.9,3.1,1.5,0.1,setosa', '4.4,3.0,1.3,0.2,setosa', '5.1,3.4,1.5,0.2,setosa', '5.0,3.5,1.3,0.3,setosa', '4.5,2.3,1.3,0.3,setosa', '4.4,3.2,1.3,0.2,setosa', '5.0,3.5,1.6,0.6,setosa', '5.1,3.8,1.9,0.4,setosa', '4.8,3.0,1.4,0.3,setosa', '5.1,3.8,1.6,0.2,setosa', '4.6,3.2,1.4,0.2,setosa', '5.3,3.7,1.5,0.2,setosa', '5.0,3.3,1.4,0.2,setosa', '7.0,3.2,4.7,1.4,versicolor', '6.4,3.2,4.5,1.5,versicolor', '6.9,3.1,4.9,1.5,versicolor', '5.5,2.3,4.0,1.3,versicolor', '6.5,2.8,4.6,1.5,versicolor', '5.7,2.8,4.5,1.3,versicolor', '6.3,3.3,4.7,1.6,versicolor', '4.9,2.4,3.3,1.0,versicolor', '6.6,2.9,4.6,1.3,versicolor', '5.2,2.7,3.9,1.4,versicolor', '5.0,2.0,3.5,1.0,versicolor', '5.9,3.0,4.2,1.5,versicolor', '6.0,2.2,4.0,1.0,versicolor', '6.1,2.9,4.7,1.4,versicolor', '5.6,2.9,3.6,1.3,versicolor', '6.7,3.1,4.4,1.4,versicolor', '5.6,3.0,4.5,1.5,versicolor', '5.8,2.7,4.1,1.0,versicolor', '6.2,2.2,4.5,1.5,versicolor', '5.6,2.5,3.9,1.1,versicolor', '5.9,3.2,4.8,1.8,versicolor', '6.1,2.8,4.0,1.3,versicolor', '6.3,2.5,4.9,1.5,versicolor', '6.1,2.8,4.7,1.2,versicolor', '6.4,2.9,4.3,1.3,versicolor', '6.6,3.0,4.4,1.4,versicolor', '6.8,2.8,4.8,1.4,versicolor', '6.7,3.0,5.0,1.7,versicolor', '6.0,2.9,4.5,1.5,versicolor', '5.7,2.6,3.5,1.0,versicolor', '5.5,2.4,3.8,1.1,versicolor', '5.5,2.4,3.7,1.0,versicolor', '5.8,2.7,3.9,1.2,versicolor', '6.0,2.7,5.1,1.6,versicolor', '5.4,3.0,4.5,1.5,versicolor', '6.0,3.4,4.5,1.6,versicolor', '6.7,3.1,4.7,1.5,versicolor', '6.3,2.3,4.4,1.3,versicolor', '5.6,3.0,4.1,1.3,versicolor', '5.5,2.5,4.0,1.3,versicolor', '5.5,2.6,4.4,1.2,versicolor', '6.1,3.0,4.6,1.4,versicolor', '5.8,2.6,4.0,1.2,versicolor', '5.0,2.3,3.3,1.0,versicolor', '5.6,2.7,4.2,1.3,versicolor', '5.7,3.0,4.2,1.2,versicolor', '5.7,2.9,4.2,1.3,versicolor', '6.2,2.9,4.3,1.3,versicolor', '5.1,2.5,3.0,1.1,versicolor', '5.7,2.8,4.1,1.3,versicolor', '6.3,3.3,6.0,2.5,virginica', '5.8,2.7,5.1,1.9,virginica', '7.1,3.0,5.9,2.1,virginica', '6.3,2.9,5.6,1.8,virginica', '6.5,3.0,5.8,2.2,virginica', '7.6,3.0,6.6,2.1,virginica', '4.9,2.5,4.5,1.7,virginica', '7.3,2.9,6.3,1.8,virginica', '6.7,2.5,5.8,1.8,virginica', '7.2,3.6,6.1,2.5,virginica', '6.5,3.2,5.1,2.0,virginica', '6.4,2.7,5.3,1.9,virginica', '6.8,3.0,5.5,2.1,virginica', '5.7,2.5,5.0,2.0,virginica', '5.8,2.8,5.1,2.4,virginica', '6.4,3.2,5.3,2.3,virginica', '6.5,3.0,5.5,1.8,virginica', '7.7,3.8,6.7,2.2,virginica', '7.7,2.6,6.9,2.3,virginica', '6.0,2.2,5.0,1.5,virginica', '6.9,3.2,5.7,2.3,virginica', '5.6,2.8,4.9,2.0,virginica', '7.7,2.8,6.7,2.0,virginica', '6.3,2.7,4.9,1.8,virginica', '6.7,3.3,5.7,2.1,virginica', '7.2,3.2,6.0,1.8,virginica', '6.2,2.8,4.8,1.8,virginica', '6.1,3.0,4.9,1.8,virginica', '6.4,2.8,5.6,2.1,virginica', '7.2,3.0,5.8,1.6,virginica', '7.4,2.8,6.1,1.9,virginica', '7.9,3.8,6.4,2.0,virginica', '6.4,2.8,5.6,2.2,virginica', '6.3,2.8,5.1,1.5,virginica', '6.1,2.6,5.6,1.4,virginica', '7.7,3.0,6.1,2.3,virginica', '6.3,3.4,5.6,2.4,virginica', '6.4,3.1,5.5,1.8,virginica', '6.0,3.0,4.8,1.8,virginica', '6.9,3.1,5.4,2.1,virginica', '6.7,3.1,5.6,2.4,virginica', '6.9,3.1,5.1,2.3,virginica', '5.8,2.7,5.1,1.9,virginica', '6.8,3.2,5.9,2.3,virginica', '6.7,3.3,5.7,2.5,virginica', '6.7,3.0,5.2,2.3,virginica', '6.3,2.5,5.0,1.9,virginica', '6.5,3.0,5.2,2.0,virginica', '6.2,3.4,5.4,2.3,virginica', '5.9,3.0,5.1,1.8,virginica']\n"
     ]
    }
   ],
   "source": [
    "# Read data from local\n",
    "irisdata = sc.textFile(\"C:/spark-3.0.0-bin-hadoop2.7/bin/dataset/irisdata.csv\")\n",
    "print(irisdata.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[5] at readRDDFromFile at PythonRDD.scala:262\n"
     ]
    }
   ],
   "source": [
    "# Import from HDFS or Parallelize Data \n",
    "# dataRead = sc.textFile('hdfs://hostname:port_number/user/username/iris.csv')\n",
    "# print(data1)\n",
    "dataRead = sc.parallelize([\"hello\", \"world !!!\"])\n",
    "print(dataRead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Object---------\n",
      "C:/spark-3.0.0-bin-hadoop2.7/bin/dataset/irisdata.csv MapPartitionsRDD[3] at textFile at <unknown>:0\n",
      "------First line------\n",
      "sepal_length,sepal_width,petal_length,petal_width,species\n",
      "------Full Data------\n",
      "['sepal_length,sepal_width,petal_length,petal_width,species', '5.1,3.5,1.4,0.2,setosa', '4.9,3.0,1.4,0.2,setosa', '4.7,3.2,1.3,0.2,setosa', '4.6,3.1,1.5,0.2,setosa', '5.0,3.6,1.4,0.2,setosa', '5.4,3.9,1.7,0.4,setosa', '4.6,3.4,1.4,0.3,setosa', '5.0,3.4,1.5,0.2,setosa', '4.4,2.9,1.4,0.2,setosa', '4.9,3.1,1.5,0.1,setosa', '5.4,3.7,1.5,0.2,setosa', '4.8,3.4,1.6,0.2,setosa', '4.8,3.0,1.4,0.1,setosa', '4.3,3.0,1.1,0.1,setosa', '5.8,4.0,1.2,0.2,setosa', '5.7,4.4,1.5,0.4,setosa', '5.4,3.9,1.3,0.4,setosa', '5.1,3.5,1.4,0.3,setosa', '5.7,3.8,1.7,0.3,setosa', '5.1,3.8,1.5,0.3,setosa', '5.4,3.4,1.7,0.2,setosa', '5.1,3.7,1.5,0.4,setosa', '4.6,3.6,1.0,0.2,setosa', '5.1,3.3,1.7,0.5,setosa', '4.8,3.4,1.9,0.2,setosa', '5.0,3.0,1.6,0.2,setosa', '5.0,3.4,1.6,0.4,setosa', '5.2,3.5,1.5,0.2,setosa', '5.2,3.4,1.4,0.2,setosa', '4.7,3.2,1.6,0.2,setosa', '4.8,3.1,1.6,0.2,setosa', '5.4,3.4,1.5,0.4,setosa', '5.2,4.1,1.5,0.1,setosa', '5.5,4.2,1.4,0.2,setosa', '4.9,3.1,1.5,0.1,setosa', '5.0,3.2,1.2,0.2,setosa', '5.5,3.5,1.3,0.2,setosa', '4.9,3.1,1.5,0.1,setosa', '4.4,3.0,1.3,0.2,setosa', '5.1,3.4,1.5,0.2,setosa', '5.0,3.5,1.3,0.3,setosa', '4.5,2.3,1.3,0.3,setosa', '4.4,3.2,1.3,0.2,setosa', '5.0,3.5,1.6,0.6,setosa', '5.1,3.8,1.9,0.4,setosa', '4.8,3.0,1.4,0.3,setosa', '5.1,3.8,1.6,0.2,setosa', '4.6,3.2,1.4,0.2,setosa', '5.3,3.7,1.5,0.2,setosa', '5.0,3.3,1.4,0.2,setosa', '7.0,3.2,4.7,1.4,versicolor', '6.4,3.2,4.5,1.5,versicolor', '6.9,3.1,4.9,1.5,versicolor', '5.5,2.3,4.0,1.3,versicolor', '6.5,2.8,4.6,1.5,versicolor', '5.7,2.8,4.5,1.3,versicolor', '6.3,3.3,4.7,1.6,versicolor', '4.9,2.4,3.3,1.0,versicolor', '6.6,2.9,4.6,1.3,versicolor', '5.2,2.7,3.9,1.4,versicolor', '5.0,2.0,3.5,1.0,versicolor', '5.9,3.0,4.2,1.5,versicolor', '6.0,2.2,4.0,1.0,versicolor', '6.1,2.9,4.7,1.4,versicolor', '5.6,2.9,3.6,1.3,versicolor', '6.7,3.1,4.4,1.4,versicolor', '5.6,3.0,4.5,1.5,versicolor', '5.8,2.7,4.1,1.0,versicolor', '6.2,2.2,4.5,1.5,versicolor', '5.6,2.5,3.9,1.1,versicolor', '5.9,3.2,4.8,1.8,versicolor', '6.1,2.8,4.0,1.3,versicolor', '6.3,2.5,4.9,1.5,versicolor', '6.1,2.8,4.7,1.2,versicolor', '6.4,2.9,4.3,1.3,versicolor', '6.6,3.0,4.4,1.4,versicolor', '6.8,2.8,4.8,1.4,versicolor', '6.7,3.0,5.0,1.7,versicolor', '6.0,2.9,4.5,1.5,versicolor', '5.7,2.6,3.5,1.0,versicolor', '5.5,2.4,3.8,1.1,versicolor', '5.5,2.4,3.7,1.0,versicolor', '5.8,2.7,3.9,1.2,versicolor', '6.0,2.7,5.1,1.6,versicolor', '5.4,3.0,4.5,1.5,versicolor', '6.0,3.4,4.5,1.6,versicolor', '6.7,3.1,4.7,1.5,versicolor', '6.3,2.3,4.4,1.3,versicolor', '5.6,3.0,4.1,1.3,versicolor', '5.5,2.5,4.0,1.3,versicolor', '5.5,2.6,4.4,1.2,versicolor', '6.1,3.0,4.6,1.4,versicolor', '5.8,2.6,4.0,1.2,versicolor', '5.0,2.3,3.3,1.0,versicolor', '5.6,2.7,4.2,1.3,versicolor', '5.7,3.0,4.2,1.2,versicolor', '5.7,2.9,4.2,1.3,versicolor', '6.2,2.9,4.3,1.3,versicolor', '5.1,2.5,3.0,1.1,versicolor', '5.7,2.8,4.1,1.3,versicolor', '6.3,3.3,6.0,2.5,virginica', '5.8,2.7,5.1,1.9,virginica', '7.1,3.0,5.9,2.1,virginica', '6.3,2.9,5.6,1.8,virginica', '6.5,3.0,5.8,2.2,virginica', '7.6,3.0,6.6,2.1,virginica', '4.9,2.5,4.5,1.7,virginica', '7.3,2.9,6.3,1.8,virginica', '6.7,2.5,5.8,1.8,virginica', '7.2,3.6,6.1,2.5,virginica', '6.5,3.2,5.1,2.0,virginica', '6.4,2.7,5.3,1.9,virginica', '6.8,3.0,5.5,2.1,virginica', '5.7,2.5,5.0,2.0,virginica', '5.8,2.8,5.1,2.4,virginica', '6.4,3.2,5.3,2.3,virginica', '6.5,3.0,5.5,1.8,virginica', '7.7,3.8,6.7,2.2,virginica', '7.7,2.6,6.9,2.3,virginica', '6.0,2.2,5.0,1.5,virginica', '6.9,3.2,5.7,2.3,virginica', '5.6,2.8,4.9,2.0,virginica', '7.7,2.8,6.7,2.0,virginica', '6.3,2.7,4.9,1.8,virginica', '6.7,3.3,5.7,2.1,virginica', '7.2,3.2,6.0,1.8,virginica', '6.2,2.8,4.8,1.8,virginica', '6.1,3.0,4.9,1.8,virginica', '6.4,2.8,5.6,2.1,virginica', '7.2,3.0,5.8,1.6,virginica', '7.4,2.8,6.1,1.9,virginica', '7.9,3.8,6.4,2.0,virginica', '6.4,2.8,5.6,2.2,virginica', '6.3,2.8,5.1,1.5,virginica', '6.1,2.6,5.6,1.4,virginica', '7.7,3.0,6.1,2.3,virginica', '6.3,3.4,5.6,2.4,virginica', '6.4,3.1,5.5,1.8,virginica', '6.0,3.0,4.8,1.8,virginica', '6.9,3.1,5.4,2.1,virginica', '6.7,3.1,5.6,2.4,virginica', '6.9,3.1,5.1,2.3,virginica', '5.8,2.7,5.1,1.9,virginica', '6.8,3.2,5.9,2.3,virginica', '6.7,3.3,5.7,2.5,virginica', '6.7,3.0,5.2,2.3,virginica', '6.3,2.5,5.0,1.9,virginica', '6.5,3.0,5.2,2.0,virginica', '6.2,3.4,5.4,2.3,virginica', '5.9,3.0,5.1,1.8,virginica']\n",
      "------First 10 lines------\n",
      "['sepal_length,sepal_width,petal_length,petal_width,species', '5.1,3.5,1.4,0.2,setosa', '4.9,3.0,1.4,0.2,setosa', '4.7,3.2,1.3,0.2,setosa', '4.6,3.1,1.5,0.2,setosa', '5.0,3.6,1.4,0.2,setosa', '5.4,3.9,1.7,0.4,setosa', '4.6,3.4,1.4,0.3,setosa', '5.0,3.4,1.5,0.2,setosa', '4.4,2.9,1.4,0.2,setosa']\n"
     ]
    }
   ],
   "source": [
    "# printing data \n",
    "print(\"--------Object---------\")\n",
    "print(irisdata) \n",
    "print(\"------First line------\")\n",
    "print(irisdata.first())\n",
    "print(\"------Full Data------\")\n",
    "print(irisdata.collect())\n",
    "print(\"------First 10 lines------\")\n",
    "print(irisdata.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/spark-3.0.0-bin-hadoop2.7/bin/dataset/irisdata.csv\n",
      "RDD_IRIS\n"
     ]
    }
   ],
   "source": [
    "# GET RDD name and SET RDD name\n",
    "print(irisdata.name())\n",
    "irisdata.setName('RDD_IRIS')\n",
    "print(irisdata.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store RDD \n",
    "irisdata.saveAsTextFile(\"C:/spark-3.0.0-bin-hadoop2.7/bin/output/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Parallelized Data and Collect-----------------\n",
      "ParallelCollectionRDD[22] at readRDDFromFile at PythonRDD.scala:262\n",
      "[('Sepal.Length', [5.1, 4.9, 4.7, 4.6]), ('Sepal.Width', [3.5, 3.0, 3.2, 3.1]), ('Species', ['setosa', 'setosa', 'setosa', 'setosa'])]\n",
      "-------------Dictionary, ans each column----------------\n",
      "{'Sepal.Length': [5.1, 4.9, 4.7, 4.6], 'Sepal.Width': [3.5, 3.0, 3.2, 3.1], 'Species': ['setosa', 'setosa', 'setosa', 'setosa']}\n",
      "[5.1, 4.9, 4.7, 4.6]\n",
      "[3.5, 3.0, 3.2, 3.1]\n",
      "['setosa', 'setosa', 'setosa', 'setosa']\n"
     ]
    }
   ],
   "source": [
    "# Converting RDD to Python Dictionary\n",
    "paralData = sc.parallelize([\n",
    "    ('Sepal.Length', [5.1,4.9,4.7,4.6]),\n",
    "    ('Sepal.Width', [3.5,3.0,3.2,3.1]),\n",
    "    ('Species', ['setosa','setosa','setosa','setosa']) \n",
    "])\n",
    "print(\"--------------Parallelized Data and Collect-----------------\")\n",
    "print(paralData)\n",
    "print(paralData.collect())\n",
    "\n",
    "dictData = paralData.collectAsMap()\n",
    "print(\"-------------Dictionary, ans each column----------------\")\n",
    "print(dictData)\n",
    "print(dictData['Sepal.Length'])\n",
    "print(dictData['Sepal.Width'])\n",
    "print(dictData['Species'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'], ['5.1', '3.5', '1.4', '0.2', 'setosa'], ['4.9', '3.0', '1.4', '0.2', 'setosa'], ['4.7', '3.2', '1.3', '0.2', 'setosa'], ['4.6', '3.1', '1.5', '0.2', 'setosa'], ['5.0', '3.6', '1.4', '0.2', 'setosa'], ['5.4', '3.9', '1.7', '0.4', 'setosa'], ['4.6', '3.4', '1.4', '0.3', 'setosa'], ['5.0', '3.4', '1.5', '0.2', 'setosa'], ['4.4', '2.9', '1.4', '0.2', 'setosa']]\n",
      "----------------------\n",
      "['sepal_length,sepal_width,petal_length,petal_width,species', '5.1,3.5,1.4,0.2,setosa', '4.9,3.0,1.4,0.2,setosa', '4.7,3.2,1.3,0.2,setosa', '4.6,3.1,1.5,0.2,setosa', '5.0,3.6,1.4,0.2,setosa', '5.4,3.9,1.7,0.4,setosa', '4.6,3.4,1.4,0.3,setosa', '5.0,3.4,1.5,0.2,setosa', '4.4,2.9,1.4,0.2,setosa']\n"
     ]
    }
   ],
   "source": [
    "# Split Data Based on Delimiter\n",
    "irisSplit = irisdata.map(lambda var1: var1.split(\",\"))\n",
    "print(irisSplit.take(10))\n",
    "print(\"----------------------\")\n",
    "print(irisdata.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'],\n",
       " ['5.1', '3.5', '1.4', '0.2', 'setosa'],\n",
       " ['4.9', '3.0', '1.4', '0.2', 'setosa'],\n",
       " ['4.7', '3.2', '1.3', '0.2', 'setosa'],\n",
       " ['4.6', '3.1', '1.5', '0.2', 'setosa'],\n",
       " ['5.0', '3.6', '1.4', '0.2', 'setosa'],\n",
       " ['5.4', '3.9', '1.7', '0.4', 'setosa'],\n",
       " ['4.6', '3.4', '1.4', '0.3', 'setosa'],\n",
       " ['5.0', '3.4', '1.5', '0.2', 'setosa'],\n",
       " ['4.4', '2.9', '1.4', '0.2', 'setosa']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate Ways of Defining Transformations and Actions - Chaining\n",
    "def functionSplit(var1):\n",
    "    return var1.split(\",\")\n",
    "sc.textFile(\"C:/spark-3.0.0-bin-hadoop2.7/bin/dataset/irisdata.csv\") .map(functionSplit) .take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal_length', '5.1', '4.9', '4.7', '4.6', '5.0', '5.4', '4.6', '5.0', '4.4']\n",
      "-------------------\n",
      "['sepal_length,sepal_width,petal_length,petal_width,species', '5.1,3.5,1.4,0.2,setosa', '4.9,3.0,1.4,0.2,setosa', '4.7,3.2,1.3,0.2,setosa', '4.6,3.1,1.5,0.2,setosa']\n",
      "['e', '.', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "# Extracting a Particular Column\n",
    "irisSplit = irisdata.map(lambda var1: var1.split(\",\"))\n",
    "irisCol0 = irisSplit.map(lambda col:col[0])\n",
    "print(irisCol0.take(10))\n",
    "irisCol1 = irisdata.map(lambda col:col[1])\n",
    "print(\"-------------------\")\n",
    "print(irisdata.take(5)) # read like a character\n",
    "print(irisCol1.take(5)) # so instead of col1 its reading 2nd character in each string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.1', '4.9', '4.7', '4.6']\n",
      "-------------------------\n",
      "[5.1, 4.9, 4.7, 4.6, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Type Casting Single Column\n",
    "print(irisdata.map(lambda var1: var1.split(\",\")).map(lambda col:col[0]).take(5)[1:])\n",
    "print(\"-------------Converting Text to float------------\")\n",
    "# The original file has header - I am not sure how to remove it, so created a new file with no header and no target variable\n",
    "print(sc.textFile(\"C:/spark-3.0.0-bin-hadoop2.7/bin/dataset/irisdataNoheader.csv\").map(lambda var1: var1.split(\";\")).map(lambda col:float(col[0])).take(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "3.6 <class 'float'>\n",
      "3.9 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "3.7 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "4.0 <class 'float'>\n",
      "4.4 <class 'float'>\n",
      "3.9 <class 'float'>\n",
      "3.5 <class 'float'>\n",
      "3.8 <class 'float'>\n",
      "3.8 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.7 <class 'float'>\n",
      "3.6 <class 'float'>\n",
      "3.3 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.5 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "4.1 <class 'float'>\n",
      "4.2 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "3.5 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.5 <class 'float'>\n",
      "2.3 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "3.5 <class 'float'>\n",
      "3.8 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.8 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "3.7 <class 'float'>\n",
      "3.3 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "2.3 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "3.3 <class 'float'>\n",
      "2.4 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "2.7 <class 'float'>\n",
      "2.0 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.2 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.7 <class 'float'>\n",
      "2.2 <class 'float'>\n",
      "2.5 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "2.5 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "2.6 <class 'float'>\n",
      "2.4 <class 'float'>\n",
      "2.4 <class 'float'>\n",
      "2.7 <class 'float'>\n",
      "2.7 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "2.3 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.5 <class 'float'>\n",
      "2.6 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.6 <class 'float'>\n",
      "2.3 <class 'float'>\n",
      "2.7 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "2.5 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "3.3 <class 'float'>\n",
      "2.7 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.5 <class 'float'>\n",
      "2.9 <class 'float'>\n",
      "2.5 <class 'float'>\n",
      "3.6 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "2.7 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.5 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.8 <class 'float'>\n",
      "2.6 <class 'float'>\n",
      "2.2 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "2.7 <class 'float'>\n",
      "3.3 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "3.8 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "2.8 <class 'float'>\n",
      "2.6 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "3.1 <class 'float'>\n",
      "2.7 <class 'float'>\n",
      "3.2 <class 'float'>\n",
      "3.3 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "2.5 <class 'float'>\n",
      "3.0 <class 'float'>\n",
      "3.4 <class 'float'>\n",
      "3.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Python For Loop with RDD Objects\n",
    "irisdata2 = sc.textFile(\"C:/spark-3.0.0-bin-hadoop2.7/bin/dataset/irisdataNoheader.csv\").map(lambda var1: var1.split(\";\"))\n",
    "for var1 in irisdata2.map(lambda var1: float(var1[1])).collect():\n",
    "    print(var1,type(var1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1, 3.5, 1.4, 0.2], [4.9, 3.0, 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2]]\n",
      "PythonRDD[113] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "# Type Casting All Columns Values\n",
    "irisModified = irisdata2.map(lambda var1: [float(var1[0]), float(var1[1]), float(var1[2]), float(var1[3])])\n",
    "print(irisModified.take(4))\n",
    "print(irisModified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('Sepal.Length', 5.1), ('Sepal.Width', 3.5), ('Petal.Length', 1.4), ('Petal.Width', 0.2)), (('Sepal.Length', 4.9), ('Sepal.Width', 3.0), ('Petal.Length', 1.4), ('Petal.Width', 0.2)), (('Sepal.Length', 4.7), ('Sepal.Width', 3.2), ('Petal.Length', 1.3), ('Petal.Width', 0.2)), (('Sepal.Length', 4.6), ('Sepal.Width', 3.1), ('Petal.Length', 1.5), ('Petal.Width', 0.2))]\n"
     ]
    }
   ],
   "source": [
    "# Creating Key-Value Pairs in RDD\n",
    "irisModified = irisdata2.map(lambda var1:(('Sepal.Length',float(var1[0])),\n",
    "                                            ('Sepal.Width',float(var1[1])),\n",
    "                                            ('Petal.Length',float(var1[2])),\n",
    "                                            ('Petal.Width',float(var1[3]))))\n",
    "print(irisModified.take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sepal.Length', 5.1), ('Sepal.Width', 3.5), ('Petal.Length', 1.4), ('Petal.Width', 0.2)]\n"
     ]
    }
   ],
   "source": [
    "# Key-Value using flat map instead of map\n",
    "irisModified = irisdata2.flatMap(lambda var1:(('Sepal.Length',float(var1[0])),\n",
    "                                           ('Sepal.Width',float(var1[1])),\n",
    "                                           ('Petal.Length',float(var1[2])),\n",
    "                                           ('Petal.Width',float(var1[3]))))\n",
    "print(irisModified.take(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4.3, 3.0, 1.1, 0.1), (4.4, 2.9, 1.4, 0.2), (4.4, 3.0, 1.3, 0.2), (4.4, 3.2, 1.3, 0.2)]\n",
      "--------------------------------------\n",
      "[(5.0, 2.0, 3.5, 1.0), (6.0, 2.2, 4.0, 1.0), (6.2, 2.2, 4.5, 1.5), (6.0, 2.2, 5.0, 1.5)]\n"
     ]
    }
   ],
   "source": [
    "# Sorting RDD \n",
    "irisModified = sc.textFile(\"C:/spark-3.0.0-bin-hadoop2.7/bin/dataset/irisdataNoheader.csv\").map(\n",
    "    lambda var1: var1.split(\";\")).map(lambda var1:(float(var1[0]), float(var1[1]), float(var1[2]), float(var1[3])))\n",
    "print(irisModified.sortBy(lambda x: x[0]).take(4))\n",
    "print(\"--------------------------------------\")\n",
    "print(irisModified.sortBy(lambda x: x[1]).take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------SL-------------\n",
      "[['Sepal.Length', 5.1], ['Sepal.Length', 4.9], ['Sepal.Length', 4.7], ['Sepal.Length', 4.6], ['Sepal.Length', 4.7], ['Sepal.Length', 4.8], ['Sepal.Length', 6.3], ['Sepal.Length', 5.6], ['Sepal.Length', 5.5], ['Sepal.Length', 5.5]]\n",
      "-------SW------------\n",
      "[['Sepal.Width', 3.5], ['Sepal.Width', 3.0], ['Sepal.Width', 3.2], ['Sepal.Width', 3.1], ['Sepal.Width', 3.2], ['Sepal.Width', 3.1], ['Sepal.Width', 2.3], ['Sepal.Width', 3.0], ['Sepal.Width', 2.5], ['Sepal.Width', 2.6]]\n",
      "--------PL-----------\n",
      "[['Petal.Length', 1.4], ['Petal.Length', 1.4], ['Petal.Length', 1.3], ['Petal.Length', 1.5], ['Petal.Length', 1.6], ['Petal.Length', 1.6], ['Petal.Length', 4.4], ['Petal.Length', 4.1], ['Petal.Length', 4.0], ['Petal.Length', 4.4]]\n",
      "--------PW-----------\n",
      "[['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 1.3], ['Petal.Width', 1.3], ['Petal.Width', 1.3], ['Petal.Width', 1.2]]\n",
      "---------Union----------\n",
      "[['Sepal.Length', 5.1], ['Sepal.Length', 4.9], ['Sepal.Length', 4.7], ['Sepal.Length', 4.6], ['Sepal.Length', 4.7], ['Sepal.Length', 4.8], ['Sepal.Length', 6.3], ['Sepal.Length', 5.6], ['Sepal.Length', 5.5], ['Sepal.Length', 5.5], ['Sepal.Length', 6.1], ['Sepal.Length', 5.8], ['Sepal.Length', 5.8], ['Sepal.Length', 6.4], ['Sepal.Length', 6.5], ['Sepal.Length', 7.7], ['Sepal.Length', 7.7], ['Sepal.Length', 6.0], ['Sepal.Width', 3.5], ['Sepal.Width', 3.0], ['Sepal.Width', 3.2], ['Sepal.Width', 3.1], ['Sepal.Width', 3.2], ['Sepal.Width', 3.1], ['Sepal.Width', 2.3], ['Sepal.Width', 3.0], ['Sepal.Width', 2.5], ['Sepal.Width', 2.6], ['Sepal.Width', 3.0], ['Sepal.Width', 2.6], ['Sepal.Width', 2.8], ['Sepal.Width', 3.2], ['Sepal.Width', 3.0], ['Sepal.Width', 3.8], ['Sepal.Width', 2.6], ['Sepal.Width', 2.2], ['Petal.Length', 1.4], ['Petal.Length', 1.4], ['Petal.Length', 1.3], ['Petal.Length', 1.5], ['Petal.Length', 1.6], ['Petal.Length', 1.6], ['Petal.Length', 4.4], ['Petal.Length', 4.1], ['Petal.Length', 4.0], ['Petal.Length', 4.4], ['Petal.Length', 4.6], ['Petal.Length', 4.0], ['Petal.Length', 5.1], ['Petal.Length', 5.3], ['Petal.Length', 5.5], ['Petal.Length', 6.7], ['Petal.Length', 6.9], ['Petal.Length', 5.0], ['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 0.2], ['Petal.Width', 1.3], ['Petal.Width', 1.3], ['Petal.Width', 1.3], ['Petal.Width', 1.2], ['Petal.Width', 1.4], ['Petal.Width', 1.2], ['Petal.Width', 2.4], ['Petal.Width', 2.3], ['Petal.Width', 1.8], ['Petal.Width', 2.2], ['Petal.Width', 2.3], ['Petal.Width', 1.5]]\n"
     ]
    }
   ],
   "source": [
    "# RDDs Union \n",
    "irisdataSplit = sc.textFile(\"C:/spark-3.0.0-bin-hadoop2.7/bin/dataset/irisdata_NoHeader.csv\").map(lambda var1: var1.split(\";\"))\n",
    "SL = irisdataSplit.map(lambda var1: ['Sepal.Length',float(var1[0])])\n",
    "SW = irisdataSplit.map(lambda var1: ['Sepal.Width',float(var1[1])])\n",
    "PL = irisdataSplit.map(lambda var1: ['Petal.Length',float(var1[2])])\n",
    "PW = irisdataSplit.map(lambda var1: ['Petal.Width',float(var1[3])])\n",
    "CV = irisdataSplit.map(lambda var1: ['Species',var1[4]])\n",
    "print(\"------SL-------------\")\n",
    "print(SL.take(10))\n",
    "print(\"-------SW------------\")\n",
    "print(SW.take(10))\n",
    "print(\"--------PL-----------\")\n",
    "print(PL.take(10))\n",
    "print(\"--------PW-----------\")\n",
    "print(PW.take(10))\n",
    "print(\"---------Union----------\")\n",
    "union_data = sc.union([SL,SW,PL,PW])\n",
    "print(union_data.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'e']\n"
     ]
    }
   ],
   "source": [
    "# Intersection \n",
    "EmployeeList = sc.parallelize(['a','b','c','d','e'])\n",
    "HealthMemberShip = sc.parallelize(['d','e','f','g'])\n",
    "print(EmployeeList.intersection(HealthMemberShip).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('employee1', ([3, 1, 2, 5, 4], [4, 5, 2, 1, 1])), ('employee2', ([2, 4, 1, 2, 2], [2, 1, 1, 1, 2]))]\n"
     ]
    }
   ],
   "source": [
    "# Join \n",
    "location1 = sc.parallelize([('employee1',[3,1,2,5,4]),('employee2',[2,4,1,2,2])])\n",
    "location2 = sc.parallelize([('employee2',[2,1,1,1,2]),('employee1',[4,5,2,1,1])])\n",
    "join1 = location1.join(location2)\n",
    "print(join1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'foreach'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-d7928002cb92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mirisModified\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mirisModified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforeach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#print(irisModified.take(4))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'foreach'"
     ]
    }
   ],
   "source": [
    "# Foreach loop \n",
    "from operator import add\n",
    "irisdata2 = sc.textFile(\"C:/spark-3.0.0-bin-hadoop2.7/bin/dataset/irisdata_NoHeader.csv\")\n",
    "irisSplit = irisdata2.map(lambda var1: var1.split(\";\"))\n",
    "irisModified = irisSplit.flatMap(lambda var1:(('Sepal.Length',float(var1[0])),\n",
    "                                              ('Sepal.Width',float(var1[1])),\n",
    "                                              ('Petal.Length',float(var1[2])),\n",
    "                                              ('Petal.Width',float(var1[3]))))\n",
    "def fun(x): \n",
    "    print(x)\n",
    "type(irisModified)\n",
    "irisModified.collect().foreach(fun)\n",
    "#print(irisModified.take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ravin'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
